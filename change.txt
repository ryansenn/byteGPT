diff --git a/.gitignore b/.gitignore
index 62c8935..633d2aa 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1 +1,2 @@
-.idea/
\ No newline at end of file
+.idea/
+changes.txt
\ No newline at end of file
diff --git a/ngram.py b/ngram.py
index 3caca0d..2c3db59 100644
--- a/ngram.py
+++ b/ngram.py
@@ -10,7 +10,7 @@ class NGram(nn.Module):
         return self.prob(x)
 
     def generate(self, x, size):
-        result = [x]
+        result = x
 
         for _ in range(size):
             logits = self.forward(x)
@@ -18,15 +18,9 @@ class NGram(nn.Module):
             prob = torch.softmax(logits, dim=-1)
             x = torch.multinomial(prob, num_samples=1) # B x 1
 
-            result.append(x)
+            result = torch.cat((result,x), dim=1)
 
-        return torch.cat(result)
+        return result
 
 
 
-model = NGram(10)
-x = torch.tensor([[1]])
-res = model.generate(x,20)
-print(res)
-
-
diff --git a/test.py b/test.py
index 7e4ce85..8c4d149 100644
--- a/test.py
+++ b/test.py
@@ -1,7 +1,9 @@
+from ngram import NGram
+from vocab import *
 import torch
 import torch.nn as nn
 
-t = torch.Tensor([[[1.0,2.0,3.0],[4.0,5.0,6.0],[7.0,8.0,9.0]],[[1.0,2.0,3.0],[4.0,5.0,6.0],[7.0,8.0,9.0]]])
-s = torch.softmax(t, dim=2)
-print(t)
-print(s)
\ No newline at end of file
+model = NGram(len(tokens))
+x = torch.tensor([[1]])
+res = model.generate(x,20)
+print(decode(res[0].tolist()))
\ No newline at end of file
diff --git a/vocab.py b/vocab.py
index e69de29..9be3861 100644
--- a/vocab.py
+++ b/vocab.py
@@ -0,0 +1,7 @@
+tokens = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 .,?!'’-+():\"\\“\\”\n"
+
+char_to_idx = {ch: i for i, ch in enumerate(tokens)}
+idx_to_char = {i: ch for i, ch in enumerate(tokens)}
+
+encode = lambda s: [char_to_idx[c] for c in s]
+decode = lambda l: ''.join([idx_to_char[i] for i in l])
\ No newline at end of file
